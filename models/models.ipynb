{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yI8ARZA-W8O8J8-t75OOAAPRIR6nW8zu"},"id":"OutxwC_tDs1O","outputId":"d5e2467f-0b9c-4213-af96-1c77df16dd0f"},"outputs":[],"source":["#@title experimentos para o journal\n","# experimentos journal\n","# feat1 = RSSIxdistance\n","# feat2 = displacement compliance\n","# feat3 = angle of arrival (exclu√≠do)\n","# comb1 = feat1, comb2 = feat2, comb3 = feat3\n","# comb4 = normfeat1 (RSSI e dist normalizados)\n","# comb5 = comb4+feat2 (RSSI e dist normalizados)\n","# comb6 = distxAoA (Transmitter Disrection)\n","# comb7 = comb6 + feat2\n","# comb8 = comb1+comb2\n","# comb9 = NEW Normalized Signal Strength 2 (Only RSSI normalized)\n","# comb10 = NSS2+DC (Only RSSI normalized)\n","# comb11 = NSS2+DC+TD (Only RSSI normalized)\n","# comb12 = NSS+DC+TD\n","# comb13 = SS+DC+TD\n","# comb14 = NSS+TD\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","import pandas as pd\n","import numpy as np\n","import time\n","import re\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import precision_recall_curve, classification_report\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, auc\n","from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay, roc_curve\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n","from itertools import cycle\n","import matplotlib.pyplot as plt\n","import joblib\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","\n","# training and test\n","windowList = ['02', '03', '08', '13', '18', '23']\n","modelMLList = ['dt', 'knn', 'rf', 'mlp', 'lstm']\n","combList = ['comb1', 'comb2', 'comb3', 'comb4', 'comb5', 'comb6', 'comb7', 'comb8', 'comb9', 'comb10', 'comb11', 'comb12', 'comb13', 'comb14']\n","labelList = ['multiclass', 'binary', 'atk_1', 'atk_2', 'atk_4', 'atk_8', 'atk_16']\n","np.random.shuffle(windowList)\n","np.random.shuffle(modelMLList)\n","np.random.shuffle(combList)\n","np.random.shuffle(labelList)\n","print(windowList)\n","print(modelMLList)\n","print(combList)\n","print(labelList)\n","for window in windowList:\n","  for modelML in modelMLList:\n","    simPath = \"/content/drive/MyDrive/dataset/veremi/veremiWithT2/simulationscsv\"\n","    journalPath = \"/content/drive/MyDrive/journal\"\n","    dismissPath = journalPath+\"/dismiss\"\n","    windowPath = dismissPath+\"/\"+window+\"bsm\"\n","    preprocPath = windowPath+\"/preprocessing\"\n","    allMsgPath = preprocPath+\"/allmsg\"\n","    modelsPath = windowPath+\"/models\"\n","    modelPath = modelsPath+\"/\"+modelML\n","    resultsPath = dismissPath+\"/results\"\n","    paths = [simPath, journalPath, dismissPath, windowPath, preprocPath, allMsgPath, modelsPath, modelPath, resultsPath]\n","    # for p in paths:\n","    #   if os.path.exists(p) == False:\n","    #     os.mkdir(p)\n","      # print(os.path.exists(p), p)\n","    for comb in combList:\n","      for label in labelList:\n","        name = window + modelML + label + comb\n","        # build performance file\n","        if os.path.exists(resultsPath+'/performance.csv'):\n","          os.chdir(resultsPath)\n","          performance = pd.read_csv('performance.csv', index_col=0)\n","        else:\n","          dataPerformance = {}\n","          performance = pd.DataFrame.from_dict(dataPerformance, orient='index', columns=['precision', 'recall', 'f1score', 'accuracy'])\n","          os.chdir(resultsPath)\n","          performance.to_csv('performance.csv')\n","\n","        # build time file\n","        if os.path.exists(resultsPath+'/time.csv'):\n","          os.chdir(resultsPath)\n","          timeRecord = pd.read_csv('time.csv', index_col=0)\n","        else:\n","          dataTime = {}\n","          timeRecord = pd.DataFrame.from_dict(dataTime, orient='index', columns=['training', 'testing'])\n","          os.chdir(resultsPath)\n","          timeRecord.to_csv('time.csv')\n","\n","\n","        while (name not in performance.index.values) or (name not in timeRecord.index.values):\n","          display(performance)\n","          print(\"-\"*70)\n","          total_exp = len(windowList)*len(modelMLList)*len(combList)*len(labelList)\n","          time_mean = timeRecord['testing'].mean() + timeRecord['training'].mean()\n","          remaining_exp = total_exp - len(timeRecord)\n","          eta = (time_mean*remaining_exp)\n","          print(f'Processing {name}... || ({len(performance)}/{total_exp}) {100*len(performance)/total_exp}%',\n","                f'|| ETA: {int(eta//3600)}:{\"{:02d}\".format(int(np.ceil(((eta/3600)%1)*60)))} h')\n","\n","          # load the data\n","          if os.path.exists(allMsgPath+\"/allMsg.csv\"):\n","            os.chdir(allMsgPath)\n","            sample = pd.read_csv('allMsg.csv', index_col=0)\n","          else:\n","            # concatenate dataset feat1 + feat2 + feat3\n","            os.chdir('/content/drive/MyDrive/journal/dismiss/aoa/preprocessing')\n","            simulations = pd.Series([f for f in os.listdir() if os.path.isfile(f)]).sort_values().reset_index(drop=True)[:]\n","            dflist = []\n","            for idx, item in enumerate(simulations):\n","              print('\\r', item, end='')\n","              df = pd.read_csv(item, index_col=0, header=0)\n","              dflist.append(df)\n","            dfaoa = pd.concat(dflist).reset_index(drop=True)\n","\n","            columns = []\n","            for i in range(int(window)):\n","              columns.append('aoa'+str(i))\n","            dfaoawindow = dfaoa[dfaoa['aoa'+str(int(window)-1)].notnull()]\n","            dfaoawindow.set_index(['sim', 'receiver', 'sender'], inplace=True)\n","\n","            os.chdir(\"/content/drive/MyDrive/globecom/dismiss/\"+window+\"bsm/preprocessing/allmsg/\")\n","            dfglobecom = pd.read_csv('allMsg.csv', index_col=0)\n","            dfglobecom.set_index(['sim', 'receiver', 'sender'], inplace=True)\n","            # dfglobecom.drop(columns=dfglobecom.filter(regex=(\"distance|RSSI\")).columns, inplace=True)\n","\n","            dfaoawindow.drop(columns=['attackerType'], inplace=True)\n","            dfaoawindow = pd.concat([dfaoawindow, dfglobecom], axis=1)\n","            dfaoawindow.reset_index(inplace=True)\n","            dfaoawindow.dropna(axis='columns',inplace=True)\n","            os.chdir(allMsgPath)\n","            dfaoawindow.to_csv('allMsg.csv')\n","\n","          columns = []\n","          # select columns\n","          # serie = number of parameter to time serie (for lstm processing)\n","          for column in sample.columns.values:\n","            if comb == 'comb1':\n","              if 'RSSI' in column:\n","                columns.append(column)\n","              elif 'distance' in column:\n","                columns.append(column)\n","              serie = 2\n","            elif comb == 'comb2':\n","              if 'conformity' in column:\n","                columns.append(column)\n","              serie = 1\n","            elif comb == 'comb3':\n","              if 'aoa' in column:\n","                columns.append(column)\n","              serie = 1\n","            elif comb == 'comb4':\n","              if 'RSSI' in column:\n","                columns.append(column)\n","              elif 'distance' in column:\n","                columns.append(column)\n","              # normalization\n","              sample[columns] = sample[columns] / sample[columns].max(axis=0)\n","              serie = 2\n","            elif comb == 'comb5':\n","              if 'RSSI' in column and 'RSSI0' not in column:\n","                columns.append(column)\n","                sample[column] = sample[column] / sample[column].max(axis=0)\n","              elif 'distance' in column and 'distance0' not in column:\n","                columns.append(column)\n","                # normalization\n","                sample[column] = sample[column] / sample[column].max(axis=0)\n","              elif 'conformity' in column and 'conformity0' not in column:\n","                columns.append(column)\n","              serie = 3\n","            elif comb == 'comb6':\n","              if 'distance' in column:\n","                columns.insert(0, column)\n","              if 'aoa' in column:\n","                columns.append(column)\n","              serie = 2\n","            elif comb == 'comb7':\n","              if 'distance' in column and 'distance0' not in column:\n","                columns.insert(0, column)\n","              if 'aoa' in column and 'aoa0' not in column:\n","                columns.append(column)\n","              if 'conformity' in column and 'conformity0' not in column:\n","                columns.append(column)\n","              serie = 3\n","            elif comb == 'comb9':\n","              # comb NSS only RSSI normalized\n","              if 'RSSI' in column:\n","                columns.append(column)\n","              if 'distance' in column:\n","                columns.append(column)\n","              # RSSI normalization\n","              columns_RSSI = sample.filter(regex=(\"RSSI\")).columns.values\n","              sample[columns_RSSI] = sample[columns_RSSI] / sample[columns_RSSI].max(axis=0)\n","              serie = 2\n","            elif comb == 'comb10':\n","              if 'RSSI' in column and 'RSSI0' not in column:\n","                columns.append(column)\n","              elif 'distance' in column and 'distance0' not in column:\n","                columns.append(column)\n","              elif 'conformity' in column and 'conformity0' not in column:\n","                columns.append(column)\n","              # RSSI normalization\n","              columns_RSSI = sample.filter(regex=(\"RSSI\")).columns.values\n","              sample[columns_RSSI] = sample[columns_RSSI] / sample[columns_RSSI].max(axis=0)\n","              serie = 3\n","          # comb11\n","          if comb == 'comb11':\n","            predictor = {\n","              'name': 'NSS+DC+TD',\n","              'fields': ['RSSI', 'distance', 'aoa', 'conformity'],\n","              'serie': 4\n","            }\n","            msg_numbers = list(range(1, int(window)))\n","            for msg_number in msg_numbers:\n","              for field in predictor['fields']:\n","                columns.append(field+str(msg_number))  \n","            # RSSI normalization\n","            columns_RSSI = sample.filter(regex=(\"RSSI\")).columns.values\n","            sample[columns_RSSI] = sample[columns_RSSI] / sample[columns_RSSI].max(axis=0)\n","            serie = predictor['serie']\n","          # comb12\n","          if comb == 'comb12':\n","            predictor = {\n","              'name': 'NSS+DC+TD',\n","              'fields': ['RSSI', 'distance', 'norm_distance', 'aoa', 'conformity'],\n","              'serie': 5\n","            }\n","            msg_numbers = list(range(1, int(window)))\n","            for msg_number in msg_numbers:\n","              for field in predictor['fields']:\n","                columns.append(field+str(msg_number))  \n","            columns_distance = sample.filter(regex=(\"distance\")).columns.values\n","            for idx, column in enumerate(columns_distance):\n","              sample['norm_distance'+str(idx)] = sample[column]\n","            # norm_distance normalization\n","            columns_norm_distance = sample.filter(regex=(\"norm_distance\")).columns.values\n","            sample[columns_norm_distance] = sample[columns_norm_distance] / sample[columns_norm_distance].max(axis=0)\n","            # RSSI normalization\n","            columns_RSSI = sample.filter(regex=(\"RSSI\")).columns.values\n","            sample[columns_RSSI] = sample[columns_RSSI] / sample[columns_RSSI].max(axis=0)\n","            serie = predictor['serie']\n","          # comb13\n","          if comb == 'comb13':\n","            predictor = {\n","              'name': 'SS+DC+TD',\n","              'fields': ['RSSI', 'distance', 'TD_distance', 'aoa', 'conformity'],\n","              'serie': 5\n","            }\n","            msg_numbers = list(range(1, int(window)))\n","            for msg_number in msg_numbers:\n","              for field in predictor['fields']:\n","                columns.append(field+str(msg_number))  \n","            columns_distance = sample.filter(regex=(\"distance\")).columns.values\n","            for idx, column in enumerate(columns_distance):\n","              sample['TD_distance'+str(idx)] = sample[column]\n","            serie = predictor['serie']\n","          # comb14\n","          if comb == 'comb14':\n","            predictor = {\n","              'name': 'NSS+TD',\n","              'fields': ['aoa', 'distance', 'norm_distance', 'RSSI'],\n","              'serie': 4\n","            }\n","            msg_numbers = list(range(0, int(window)))\n","            for msg_number in msg_numbers:\n","              for field in predictor['fields']:\n","                columns.append(field+str(msg_number))  \n","            columns_distance = sample.filter(regex=(\"distance\")).columns.values\n","            for idx, column in enumerate(columns_distance):\n","              sample['norm_distance'+str(idx)] = sample[column]\n","            # norm_distance normalization\n","            columns_norm_distance = sample.filter(regex=(\"norm_distance\")).columns.values\n","            sample[columns_norm_distance] = sample[columns_norm_distance] / sample[columns_norm_distance].max(axis=0)\n","            # RSSI normalization\n","            columns_RSSI = sample.filter(regex=(\"RSSI\")).columns.values\n","            sample[columns_RSSI] = sample[columns_RSSI] / sample[columns_RSSI].max(axis=0)\n","            serie = predictor['serie']\n","          # intercalate\n","          if comb == 'comb6':\n","            split = []\n","            order = []\n","            for idx, c in enumerate(columns):\n","              split.append(re.split('(\\d+)', c))\n","            for i in range(int(window)):\n","              for idx, item in enumerate(split):\n","                if int(item[1]) == i:\n","                  order.append(idx)\n","            columns = [columns[i] for i in order]\n","            # columns.remove('aoa0')\n","          elif comb == 'comb7':\n","            split = []\n","            order = []\n","            for idx, c in enumerate(columns):\n","              split.append(re.split('(\\d+)', c))\n","            for i in range(int(window)):\n","              for idx, item in enumerate(split):\n","                if int(item[1]) == i:\n","                  order.append(idx)\n","            columns = [columns[i] for i in order]\n","          # add label\n","          columns.append('attackerType')\n","        \n","          if label == 'multiclass':\n","            sample = sample[columns]\n","          elif label == 'binary':\n","            posLabel = 1\n","            sample = sample[columns]\n","            sample['attackerType'].loc[sample['attackerType'] != 0] = posLabel\n","          else:\n","            posLabel = int(label.split(\"_\")[1])\n","            sample = sample[columns]\n","            sample = sample.loc[(sample['attackerType'] == 0) | (sample['attackerType'] == posLabel)]\n","          # select the data\n","          data = sample.iloc[:, 0:-1].values\n","          classes = sample.iloc[:, -1].values\n","          # label binarize one-hot style\n","          lb = preprocessing.LabelBinarizer()\n","          lb.fit(classes)\n","          if modelML in ['mlp', 'lstm'] and label == 'multiclass':\n","            classes = lb.transform(classes)\n","          elif modelML in ['mlp', 'lstm']:\n","            classes = lb.transform(classes)\n","            classes = MultiLabelBinarizer().fit_transform(classes)\n","          data_train, data_test, classes_train, classes_test = train_test_split(data, classes, train_size=0.8, test_size=0.2, random_state=1)\n","          if os.path.exists(modelPath+\"/\"+label) == False:\n","            os.mkdir(modelPath+\"/\"+label)\n","          clf = []\n","          if modelML == 'dt':\n","            clf = DecisionTreeClassifier()\n","          elif modelML == 'knn':\n","            clf = KNeighborsClassifier()\n","          elif modelML == 'rf':\n","            clf = RandomForestClassifier()\n","          elif modelML == 'mlp':\n","            # modelo rede neural\n","            layer1 = keras.layers.Input(shape=(data_train.shape[1],))\n","            layer2 = keras.layers.Dense(7, activation=\"relu\")(layer1)\n","            layer3 = keras.layers.Dense(7, activation=\"relu\")(layer2)\n","            output = keras.layers.Dense(classes_train.shape[1], activation=\"softmax\")(layer3)\n","          elif modelML == 'lstm':\n","            data_train=data_train.reshape(data_train.shape[0], int(data_train.shape[1]/serie), serie)\n","            data_test=data_test.reshape(data_test.shape[0], int(data_test.shape[1]/serie), serie)\n","            lstmunits = 32\n","            layer1 = keras.layers.Input(shape=(data_train.shape[1], data_train.shape[2]))\n","            layer2 = keras.layers.LSTM(lstmunits, return_sequences=True)(layer1)\n","            layer3 = keras.layers.LSTM(lstmunits)(layer2)\n","            output = keras.layers.Dense(classes_train.shape[1], activation=\"softmax\")(layer3)\n","\n","          if modelML in ['mlp', 'lstm']:\n","            clf = keras.Model(inputs=layer1, outputs=output, name=name)\n","            clf.compile(\n","                  loss=keras.losses.CategoricalCrossentropy(),\n","                  optimizer=keras.optimizers.Adam(),\n","                  metrics=[keras.metrics.Accuracy(),\n","                          keras.metrics.Recall(class_id=1)],\n","              )\n","            early_stopping = keras.callbacks.EarlyStopping(\n","                monitor=\"loss\",\n","                patience=3,\n","                min_delta=1e-4,\n","                restore_best_weights=True\n","            )\n","            # check condition for training\n","            while (os.path.exists(modelPath+\"/\"+label+\"/\"+comb+'/saved_model.pb') == False) or (name not in timeRecord.index.values):\n","              print('training', name)\n","              start_time = time.time()\n","              clf.fit(\n","                  data_train,\n","                  classes_train,\n","                  epochs=200,\n","                  batch_size=1000,\n","                  callbacks=[early_stopping]\n","              )\n","              trainingTime = time.time() - start_time\n","              clf.save(modelPath+\"/\"+label+\"/\"+comb)\n","              \n","              dataTime = {}\n","              dataTime[name] = [trainingTime, np.nan]\n","              dfTime = pd.DataFrame.from_dict(dataTime, orient='index', columns=['training', 'testing'])\n","              while name not in timeRecord.index.values:\n","                os.chdir(resultsPath)\n","                timeRecord = pd.read_csv('time.csv', index_col=0)\n","                timeRecord.loc[name] = dfTime.loc[name]\n","                timeRecord.to_csv('time.csv')\n","                timeRecord = pd.read_csv('time.csv', index_col=0)\n","              \n","              \n","          elif modelML in ['dt', 'knn', 'rf', 'svm']:\n","            # check condition for training\n","            while (os.path.exists(modelPath+\"/\"+label+\"/\"+name+'fit.pkl') == False) or (name not in timeRecord.index.values):\n","              print('training', name)\n","              start_time = time.time()\n","              clf.fit(data_train, classes_train)\n","              trainingTime = time.time() - start_time\n","              os.chdir(modelPath+\"/\"+label)\n","              joblib.dump(clf, name+'fit.pkl')\n","              \n","              \n","              dataTime = {}\n","              dataTime[name] = [trainingTime, np.nan]\n","              dfTime = pd.DataFrame.from_dict(dataTime, orient='index', columns=['training', 'testing'])\n","              while name not in timeRecord.index.values:\n","                os.chdir(resultsPath)\n","                timeRecord = pd.read_csv('time.csv', index_col=0)\n","                timeRecord.loc[name] = dfTime.loc[name]\n","                timeRecord.to_csv('time.csv')\n","                timeRecord = pd.read_csv('time.csv', index_col=0)            \n","              \n","              \n","\n","          os.chdir(resultsPath)\n","          timeRecord = pd.read_csv('time.csv', index_col=0)\n","          print('Training '+name+' done in', \"{:.2f}\".format(timeRecord['training'].loc[name])+' sec')\n","\n","          if name in timeRecord.index.values:  \n","            # test\n","            os.chdir(modelPath+\"/\"+label)\n","            clf = []\n","            if modelML in ['dt', 'knn', 'rf', 'svm']:\n","              clf = joblib.load(name+'fit.pkl' , mmap_mode ='r')\n","              proba = []\n","              start_time = time.time()\n","              proba = clf.predict_proba(data_test)\n","              predictTime = time.time() - start_time\n","              clTest = classes_test\n","            elif modelML in ['mlp', 'lstm']:\n","              clf = keras.models.load_model(modelPath+\"/\"+label+\"/\"+comb)\n","              proba = []\n","              start_time = time.time()\n","              proba = clf.predict(data_test)\n","              predictTime = time.time() - start_time\n","              clTest = lb.inverse_transform(classes_test)\n","            \n","            # log time of testing\n","            timeRecord['testing'].loc[name] = predictTime\n","            os.chdir(resultsPath)\n","            timeRecord.to_csv('time.csv')\n","            print('Predict '+name+' done in ', \"{:.2f}\".format(predictTime)+' sec')\n","            print(\"-\"*70)\n","\n","            if label == 'multiclass':\n","              # Classification Report\n","              pred = lb.inverse_transform(proba)\n","            else:\n","              # Best threshold\n","              precision, recall, thresholds = precision_recall_curve(clTest, proba[:, 1], pos_label=posLabel)\n","              # convert to f score\n","              np.seterr(divide='ignore', invalid='ignore')\n","              fscore = (2 * precision * recall) / (precision + recall)\n","              np.nan_to_num(fscore, copy=False)\n","              # locate the index of the largest f score\n","              ix = np.argmax(fscore)\n","              print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n","              print(\"-\"*70)\n","              # Classification Report\n","              pred = np.where(np.array(proba[:, 1]) >= thresholds[ix], posLabel, 0)\n","            classlist = []\n","            for cl in lb.classes_:\n","              classlist.append('class '+str(int(cl)))\n","            print('Classification Report for '+name)\n","            print(classification_report(clTest,\n","                                        pred,\n","                                        target_names=classlist,\n","                                        digits=3,\n","                                        zero_division=0))\n","            print(\"-\"*70)\n","            # Confusion matrix\n","            cm = confusion_matrix(clTest, pred, labels=lb.classes_)\n","            disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n","                                          display_labels=lb.classes_)\n","            disp.plot()\n","            plt.title(name)\n","            plt.savefig(name+'.pdf')\n","            plt.show()\n","            print(\"-\"*70)\n","\n","            if label == 'multiclass':\n","              # ROC CURVES\n","              if modelML in ['dt', 'knn', 'rf', 'svm']:\n","                lbclasses_test = lb.transform(classes_test)\n","              elif modelML in ['mlp', 'lstm']:\n","                lbclasses_test = classes_test\n","              n_classes = lbclasses_test.shape[1]\n","              # Compute ROC curve and ROC area for each class\n","              fpr = dict()\n","              tpr = dict()\n","              roc_auc = dict()\n","              for i in range(n_classes):\n","                  fpr[i], tpr[i], _ = roc_curve(lbclasses_test[:, i], proba[:, i])\n","                  roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","              # First aggregate all false positive rates\n","              all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","\n","              # Then interpolate all ROC curves at this points\n","              mean_tpr = np.zeros_like(all_fpr)\n","              for i in range(n_classes):\n","                  mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","\n","              # Finally average it and compute AUC\n","              mean_tpr /= n_classes\n","\n","              fpr[\"macro\"] = all_fpr\n","              tpr[\"macro\"] = mean_tpr\n","              roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","              # Plot all ROC curves\n","              lw = 2\n","              plt.figure()\n","              # plt.plot(\n","              #     fpr[\"micro\"],\n","              #     tpr[\"micro\"],\n","              #     label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n","              #     color=\"deeppink\",\n","              #     linestyle=\":\",\n","              #     linewidth=4,\n","              # )\n","\n","              plt.plot(\n","                  fpr[\"macro\"],\n","                  tpr[\"macro\"],\n","                  label=\"Macro Avg (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n","                  color=\"navy\",\n","                  linestyle=\":\",\n","                  linewidth=4,\n","                  alpha=0.5,\n","              )\n","\n","              colors = cycle([\"b\", \"g\", \"r\", \"c\", \"m\", \"y\"])\n","              for i, color in zip(range(n_classes), colors):\n","                  labelClasses = int(lb.classes_[i])\n","\n","                  plt.plot(\n","                      fpr[i],\n","                      tpr[i],\n","                      color=color,\n","                      lw=lw,\n","                      label=\"Class {0} (area = {1:0.2f})\".format(labelClasses, roc_auc[i]),\n","                      alpha=0.5\n","                  )\n","\n","              plt.plot([0, 1], [0, 1], \"k--\", lw=lw, color=\"grey\", alpha=0.2)\n","              plt.xlim([-0.02, 1.0])\n","              plt.ylim([0.0, 1.05])\n","              plt.xlabel(\"False Positive Rate\")\n","              plt.ylabel(\"True Positive Rate\")\n","              plt.legend(loc=\"lower right\")\n","              plt.title('ROCcurve '+name)\n","              os.chdir(modelPath+\"/\"+label)\n","              plt.savefig('ROCcurve '+name+'.pdf')\n","              plt.show()\n","              print(\"-\"*70)\n","\n","\n","              # PR CURVES\n","              # Compute PR curve and PR area for each class\n","              precision = dict()\n","              recall = dict()\n","              pr_auc = dict()\n","              # precision, recall, thresholds = precision_recall_curve(clTest, proba[:, 1], pos_label=posLabel)\n","              for i in range(n_classes):\n","                  precision[i], recall[i], _ = precision_recall_curve(lbclasses_test[:, i], proba[:, i])\n","                  pr_auc[i] = auc(recall[i], precision[i])\n","\n","              # First aggregate all false positive rates\n","              all_precision = np.unique(np.concatenate([precision[i] for i in range(n_classes)]))\n","\n","              # Then interpolate all pr curves at this points\n","              mean_recall = np.zeros_like(all_precision)\n","              for i in range(n_classes):\n","                  mean_recall += np.interp(all_precision, precision[i], recall[i])\n","\n","              # Finally average it and compute AUC\n","              mean_recall /= n_classes\n","\n","              precision[\"macro\"] = all_precision\n","              recall[\"macro\"] = mean_recall\n","              try:\n","                pr_auc[\"macro\"] = auc(recall[\"macro\"], precision[\"macro\"])\n","              except ValueError:\n","                timeRecord.drop(name, inplace=True)\n","                continue\n","\n","              # Plot all pr curves\n","              lw = 2\n","              plt.figure()\n","              # plt.plot(\n","              #     precision[\"micro\"],\n","              #     recall[\"micro\"],\n","              #     label=\"micro-average pr curve (area = {0:0.2f})\".format(pr_auc[\"micro\"]),\n","              #     color=\"deeppink\",\n","              #     linestyle=\":\",\n","              #     linewidth=4,\n","              # )\n","\n","              plt.plot(\n","                  precision[\"macro\"],\n","                  recall[\"macro\"],\n","                  label=\"Macro Avg (area = {0:0.2f})\".format(pr_auc[\"macro\"]),\n","                  color=\"navy\",\n","                  linestyle=\":\",\n","                  linewidth=4,\n","                  alpha=0.5,\n","              )\n","\n","              colors = cycle([\"b\", \"g\", \"r\", \"c\", \"m\", \"y\"])\n","              for i, color in zip(range(n_classes), colors):\n","                  labelClasses = int(lb.classes_[i])\n","\n","                  plt.plot(\n","                      precision[i],\n","                      recall[i],\n","                      color=color,\n","                      lw=lw,\n","                      label=\"Class {0} (area = {1:0.2f})\".format(labelClasses, pr_auc[i]),\n","                      alpha=0.5\n","                  )\n","\n","              plt.xlim([0.15, 1.02])\n","              plt.ylim([-0.01, 1.05])\n","              plt.xlabel(\"False Positive Rate\")\n","              plt.ylabel(\"True Positive Rate\")\n","              plt.legend(loc=\"lower left\")\n","              plt.title('PRcurve '+name)\n","              os.chdir(modelPath+\"/\"+label)\n","              plt.savefig('PRcurve '+name+'.pdf')\n","              plt.show()\n","              print(\"-\"*70)\n","\n","            else:\n","              # Precision-Recall curve\n","              PrecisionRecallDisplay.from_predictions(clTest, proba[:, 1], pos_label=posLabel)\n","              plt.title('PR curve '+name)\n","              no_skill = len(clTest[clTest==1]) / len(clTest)\n","              plt.plot([0,1], [no_skill,no_skill], linestyle='--', color=\"grey\", label='No Skill')\n","              plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best threshold')\n","              plt.legend()\n","              plt.savefig('PRcurve '+name+'.pdf')\n","              plt.show()\n","              print(\"-\"*70)\n","              # ROC curve\n","              RocCurveDisplay.from_predictions(clTest, proba[:, 1], pos_label=posLabel)\n","              plt.title('ROC curve '+name)\n","              plt.plot([0, 1], [0, 1], color=\"grey\", lw=1, linestyle=\"--\")\n","              plt.savefig('ROCcurve '+name+'.pdf')\n","              plt.show()\n","              print(\"-\"*70)\n","\n","            # save the results to a csv\n","            if label == 'multiclass':\n","              prScore = precision_score(clTest, pred, average='macro', zero_division=0)\n","              rcScore = recall_score(clTest, pred, average='macro', zero_division=0)\n","              f1Score = f1_score(clTest, pred, average='macro', zero_division=0)\n","              accScore = accuracy_score(clTest, pred)\n","            else:\n","              prScore = precision_score(clTest, pred, pos_label=posLabel, zero_division=0)\n","              rcScore = recall_score(clTest, pred, pos_label=posLabel, zero_division=0)\n","              f1Score = f1_score(clTest, pred, pos_label=posLabel, zero_division=0)\n","              accScore = accuracy_score(clTest, pred)\n","            dataPerformance = {}\n","            dataPerformance[name] = [prScore, rcScore, f1Score, accScore]\n","\n","            dfPerformance = pd.DataFrame.from_dict(dataPerformance, orient='index', columns=['precision', 'recall', 'f1score', 'accuracy'])\n","\n","            os.chdir(resultsPath)\n","            performance = pd.read_csv('performance.csv', index_col=0)\n","            try:\n","              performance.loc[name] = dfPerformance.loc[name]\n","            except KeyError:\n","              performance = pd.concat([performance, dfPerformance])\n","            performance.to_csv('performance.csv')\n","\n","print('performance.csv')\n","display(performance)\n","print(\"-\"*70)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2210,"status":"ok","timestamp":1666871162575,"user":{"displayName":"Fernando da Silva Dutra","userId":"15997828973746649324"},"user_tz":180},"id":"gQhW8FlE24SF","outputId":"a5f96b65-0ce5-442e-81c4-4cf8fea309d5"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","import pandas as pd\n","import numpy as np\n","import time\n","import re\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import precision_recall_curve, classification_report\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, auc\n","from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay, roc_curve\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n","from itertools import cycle\n","import matplotlib.pyplot as plt\n","import joblib\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","windowList = ['02', '03', '08', '13', '18', '23']\n","modelMLList = ['dt']\n","combList = ['comb14']\n","labelList = ['multiclass', 'binary', 'atk_1', 'atk_2', 'atk_4', 'atk_8', 'atk_16']\n","for window in windowList:\n","  for modelML in modelMLList:\n","    for comb in combList:\n","      for label in labelList:\n","        name = window + modelML + label + comb\n","        simPath = \"/content/drive/MyDrive/dataset/veremi/veremiWithT2/simulationscsv\"\n","        journalPath = \"/content/drive/MyDrive/journal\"\n","        dismissPath = journalPath+\"/dismiss\"\n","        windowPath = dismissPath+\"/\"+window+\"bsm\"\n","        preprocPath = windowPath+\"/preprocessing\"\n","        allMsgPath = preprocPath+\"/allmsg\"\n","        modelsPath = windowPath+\"/models\"\n","        modelPath = modelsPath+\"/\"+modelML\n","        resultsPath = dismissPath+\"/results\"\n","        if os.path.exists(modelPath+\"/\"+label+\"/\"+name+'fit.pkl'):\n","          os.remove(modelPath+\"/\"+label+\"/\"+name+'fit.pkl')\n","          print(name, os.path.exists(modelPath+\"/\"+label+\"/\"+name+'fit.pkl'))\n","        if os.path.exists(modelPath+\"/\"+label+\"/\"+comb+'/saved_model.pb'):\n","          os.remove(modelPath+\"/\"+label+\"/\"+comb+'/saved_model.pb')\n","          print(name, os.path.exists(modelPath+\"/\"+label+\"/\"+comb+'/saved_model.pb'))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMjTLhUHBG1/zZqmOD+v5p7","collapsed_sections":[],"machine_shape":"hm","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
